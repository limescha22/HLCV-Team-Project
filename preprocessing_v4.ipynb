{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412747f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch, torchvision, torchvision.transforms.v2 as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "import random\n",
    "\n",
    "# Defining paths\n",
    "\n",
    "TRAIN_DATA_DIR = os.path.join(\"data/train\")\n",
    "VAL_DATA_DIR = os.path.join(\"data/val\")\n",
    "\n",
    "CLEAN_TRAIN_DATA_DIR = os.path.join(\"clean/train\")\n",
    "CLEAN_VAL_DATA_DIR = os.path.join(\"clean/val\")\n",
    "\n",
    "OUTPUT_BASE = \"data_augmented\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)\n",
    "\n",
    "# --- CONFIG ---\n",
    "IMG_SIZE = (150, 150)\n",
    "OUTPUT_BASE = \"data_augmented\"\n",
    "SINGLE_DIR = os.path.join(OUTPUT_BASE, \"single_various_augmentation\")\n",
    "MULTI_DIR = os.path.join(OUTPUT_BASE, \"multiple_various_augmentation\")\n",
    "\n",
    "# make sure base directories exist\n",
    "os.makedirs(SINGLE_DIR, exist_ok=True)\n",
    "os.makedirs(MULTI_DIR, exist_ok=True)\n",
    "\n",
    "# --- Strong augmentation parameters ---\n",
    "STRONG_PARAMS = {\n",
    "    \"rotation\": (-45, 45),              # degrees\n",
    "    \"translation\": (-0.4, 0.4),         # fraction of image size\n",
    "    \"scaling\": (0.8, 1.2),              # zoom\n",
    "    \"shear\": (-25, 25),                 # degrees\n",
    "    \"h_flip\": 0.5,                       # probability\n",
    "    \"v_flip\": 0.3,                       # probability\n",
    "    \"brightness\": (0.6, 1.4),            # only RGB\n",
    "    \"contrast\": (0.6, 1.5),              # only RGB\n",
    "    \"noise_std\": (0.05, 0.1),            # Gaussian noise\n",
    "    \"blur_radius\": (1, 2)                # Gaussian blur\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b81f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_image(img, apply_prob=0.6, grayscale_prob=0.5):\n",
    "    \"\"\"Apply strong, probabilistic augmentations on a single image.\n",
    "    img: PIL Image\n",
    "    apply_prob: probability to apply each augmentation\n",
    "    grayscale_prob: probability to convert to grayscale\n",
    "    \"\"\"\n",
    "    img_aug = img.copy()\n",
    "    \n",
    "    # Decide grayscale\n",
    "    is_grayscale = random.random() < grayscale_prob\n",
    "    if is_grayscale:\n",
    "        img_aug = img_aug.convert(\"L\").convert(\"RGB\")  # keep 3 channels\n",
    "    \n",
    "    width, height = img_aug.size\n",
    "    img_np = np.array(img_aug)\n",
    "\n",
    "    # --- Geometric / spatial transformations ---\n",
    "    # Rotation\n",
    "    if random.random() < apply_prob:\n",
    "        angle = random.uniform(*STRONG_PARAMS[\"rotation\"])\n",
    "        M = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)\n",
    "        img_np = cv2.warpAffine(img_np, M, (width, height), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    # Translation\n",
    "    if random.random() < apply_prob:\n",
    "        tx = random.uniform(*STRONG_PARAMS[\"translation\"]) * width\n",
    "        ty = random.uniform(*STRONG_PARAMS[\"translation\"]) * height\n",
    "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        img_np = cv2.warpAffine(img_np, M, (width, height), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    # Scaling\n",
    "    if random.random() < apply_prob:\n",
    "        scale = random.uniform(*STRONG_PARAMS[\"scaling\"])\n",
    "        img_np = cv2.resize(img_np, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        # Crop or pad to original size\n",
    "        h, w = img_np.shape[:2]\n",
    "        if h > height:\n",
    "            start = (h - height)//2\n",
    "            img_np = img_np[start:start+height, :]\n",
    "        elif h < height:\n",
    "            pad_top = (height - h)//2\n",
    "            pad_bottom = height - h - pad_top\n",
    "            img_np = cv2.copyMakeBorder(img_np, pad_top, pad_bottom, 0, 0, cv2.BORDER_REFLECT)\n",
    "        if w > width:\n",
    "            start = (w - width)//2\n",
    "            img_np = img_np[:, start:start+width]\n",
    "        elif w < width:\n",
    "            pad_left = (width - w)//2\n",
    "            pad_right = width - w - pad_left\n",
    "            img_np = cv2.copyMakeBorder(img_np, 0, 0, pad_left, pad_right, cv2.BORDER_REFLECT)\n",
    "\n",
    "    # Shear\n",
    "    if random.random() < apply_prob:\n",
    "        shear_angle = np.deg2rad(random.uniform(*STRONG_PARAMS[\"shear\"]))\n",
    "        M = np.array([[1, np.tan(shear_angle), 0],\n",
    "                      [0, 1, 0]], dtype=np.float32)\n",
    "        img_np = cv2.warpAffine(img_np, M, (width, height), borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    # Flips\n",
    "    if random.random() < STRONG_PARAMS[\"h_flip\"]:\n",
    "        img_np = cv2.flip(img_np, 1)\n",
    "    if random.random() < STRONG_PARAMS[\"v_flip\"]:\n",
    "        img_np = cv2.flip(img_np, 0)\n",
    "\n",
    "    # --- Color / photometric transformations (skip if grayscale) ---\n",
    "    img_aug = Image.fromarray(img_np)\n",
    "    if not is_grayscale:\n",
    "        # Brightness\n",
    "        if random.random() < apply_prob:\n",
    "            factor = random.uniform(*STRONG_PARAMS[\"brightness\"])\n",
    "            img_aug = ImageEnhance.Brightness(img_aug).enhance(factor)\n",
    "        # Contrast\n",
    "        if random.random() < apply_prob:\n",
    "            factor = random.uniform(*STRONG_PARAMS[\"contrast\"])\n",
    "            img_aug = ImageEnhance.Contrast(img_aug).enhance(factor)\n",
    "\n",
    "    img_np = np.array(img_aug)\n",
    "\n",
    "    # --- Noise ---\n",
    "    if random.random() < apply_prob:\n",
    "        noise_std = random.uniform(*STRONG_PARAMS[\"noise_std\"])\n",
    "        noise = np.random.normal(0, noise_std*255, img_np.shape).astype(np.float32)\n",
    "        img_np = np.clip(img_np.astype(np.float32)+noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # --- Blur ---\n",
    "    if random.random() < apply_prob:\n",
    "        radius = random.randint(*STRONG_PARAMS[\"blur_radius\"])\n",
    "        img_aug = Image.fromarray(img_np)\n",
    "        img_aug = img_aug.filter(Image.Filter.GaussianBlur(radius))\n",
    "        img_np = np.array(img_aug)\n",
    "\n",
    "    return Image.fromarray(img_np)\n",
    "\n",
    "def augment_and_save_dataset(TRAIN_DATA_DIR, OUTPUT_DIR, variants_per_image=6, apply_prob=0.6, grayscale_prob=0.5, img_size=(150,150)):\n",
    "    \"\"\"Augment all images in TRAIN_DATA_DIR and save to OUTPUT_DIR.\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    class_names = [d for d in os.listdir(TRAIN_DATA_DIR) if os.path.isdir(os.path.join(TRAIN_DATA_DIR, d))]\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_input_dir = os.path.join(TRAIN_DATA_DIR, cls)\n",
    "        cls_output_dir = os.path.join(OUTPUT_DIR, cls)\n",
    "        os.makedirs(cls_output_dir, exist_ok=True)\n",
    "\n",
    "        img_files = [f for f in os.listdir(cls_input_dir) if f.lower().endswith((\".jpg\",\".png\",\".jpeg\"))]\n",
    "\n",
    "        for img_file in tqdm(img_files, desc=f\"Class {cls}\"):\n",
    "            img_path = os.path.join(cls_input_dir, img_file)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.resize(img_size)\n",
    "\n",
    "            for i in range(variants_per_image):\n",
    "                aug_img = augment_image(img, apply_prob=apply_prob, grayscale_prob=grayscale_prob)\n",
    "                base_name = os.path.splitext(img_file)[0]\n",
    "                save_path = os.path.join(cls_output_dir, f\"{base_name}_aug_{i+1}.jpg\")\n",
    "                aug_img.save(save_path, \"JPEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b29cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define output directory ---\n",
    "OUTPUT_DIR = \"data_augmented/strong_mix_match\"\n",
    "\n",
    "# --- Call the augmentation function ---\n",
    "augment_and_save_dataset(\n",
    "    TRAIN_DATA_DIR=TRAIN_DATA_DIR,    # your existing training data\n",
    "    OUTPUT_DIR=OUTPUT_DIR,            # where to save augmented images\n",
    "    variants_per_image=6,             # how many augmented versions per original\n",
    "    apply_prob=0.6,                   # probability of each augmentation being applied\n",
    "    grayscale_prob=0.5,               # probability of converting to grayscale\n",
    "    img_size=(150, 150)               # final resize dimension\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Augmentation complete! All images saved under: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "BATCH_SIZE = 320\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = 10\n",
    "DATA_AUG_DIR = OUTPUT_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710509ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load training dataset ---\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    OUTPUT_DIR,\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# --- Resize validation dataset to match training ---\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DATA_DIR,\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# --- Define CNN model ---\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(5, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(5, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(5, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(5, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --- Callbacks ---\n",
    "checkpoint_path = os.path.join(OUTPUT_DIR, f\"best_model_{OUTPUT_DIR}.keras\")\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- Store best validation accuracy ---\n",
    "best_val_loss = max(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlcvtp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
